{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to diviser the text into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['To', 'Sherlock', 'Holmes', 'she', 'is', 'always', '_the_', 'woman', '.', 'I']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "filename = \"sherlock_holmes_1.txt\"\n",
    "file = open(filename, \"r\", encoding=\"utf-8\")\n",
    "text = file.read()\n",
    "text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "# diviser le text en mot\n",
    "words = nltk.tokenize.word_tokenize(text)\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets und Short Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Central', 'Park', 'Tower', 'is', 'reaaally', 'hiiigh']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# initialiser la variable tweet\n",
    "tweet = \"@EmpireStateBldg Central Park Tower is reaaaally hiiiigh\"\n",
    "\n",
    "# divise le text en word, respectant la casse, réduire la longueur, strip the handles\n",
    "words = nltk.tokenize.casual.casual_tokenize(tweet, \n",
    "                                             preserve_case=True, \n",
    "                                             reduce_len=True, \n",
    "                                             strip_handles=True)\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diviser le text en mot avec: spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To Sherlock Holmes she is always _the_ woman. I have seldom heard him mention her under any other name. In his eyes she eclipses and predominates the whole of her sex. It was not that he felt any emotion akin to love for Irene Adler. All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind. He was, I take it, the most perfect reasoning and observing machine that the world has seen, but as a lover he would have placed himself in a false position. He never spoke of the softer passions, save with a gibe and a sneer. They were admirable things for the observer—excellent for drawing the veil from men’s motives and actions. But for the trained reasoner to admit such intrusions into his own delicate and finely adjusted temperament was to introduce a distracting factor which might throw a doubt upon all his mental results. Grit in a sensitive instrument, or a crack in one of his own high-power lenses, would not be more disturbing than a strong emotion in a nature such as his. And yet there was but one woman to him, and that woman was the late Irene Adler, of dubious and questionable memory.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "filename = \"sherlock_holmes_1.txt\"\n",
    "file = open(filename, \"r\", encoding=\"utf-8\")\n",
    "text = file.read()\n",
    "text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "# initialisation du moteur spacy et utilisation du model Englais\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# divise le text en mot\n",
    "doc = nlp(text)\n",
    "words = [token.text for token in doc]\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Labelliser chaque mot du text en précisant sa fonction  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('To', 'ADP'),\n",
       " ('Sherlock', 'PROPN'),\n",
       " ('Holmes', 'PROPN'),\n",
       " ('she', 'PRON'),\n",
       " ('is', 'AUX'),\n",
       " ('always', 'ADV'),\n",
       " ('_', 'PUNCT'),\n",
       " ('the', 'DET'),\n",
       " ('_', 'DET'),\n",
       " ('woman', 'NOUN')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "filename = \"sherlock_holmes_1.txt\"\n",
    "file = open(filename, \"r\", encoding=\"utf-8\")\n",
    "text = file.read()\n",
    "text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "# initialisation du moteur spacy en anglais\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# diviser le text en mots\n",
    "doc = nlp(text)\n",
    "words = [token.text for token in doc]\n",
    "\n",
    "# trouver la position de chaque mot\n",
    "pos = [token.pos_ for token in doc]\n",
    "words_pos_tuple = list(zip(words, pos))\n",
    "words_pos_tuple[:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Labelliser chaque mot du text en précisant sa fonction : NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('To', 'TO'),\n",
       " ('Sherlock', 'NNP'),\n",
       " ('Holmes', 'NNP'),\n",
       " ('she', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('always', 'RB'),\n",
       " ('_the_', 'JJ'),\n",
       " ('woman', 'NN'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# télécharger le perceptron\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "filename = \"sherlock_holmes_1.txt\"\n",
    "file = open(filename, \"r\", encoding=\"utf-8\")\n",
    "text = file.read()\n",
    "text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "# tokenize le text en mot\n",
    "words = nltk.tokenize.word_tokenize(text)\n",
    "\n",
    "# la position du mot\n",
    "word_with_pos = nltk.pos_tag(words)\n",
    "word_with_pos[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word stemming:\n",
    "Retirer les terminaisons tel que -ing and -ed. Mettre le mot a l infinitif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['leaf', 'leav', 'book', 'write', 'complet', 'stem', 'sky']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "# initialiser le stemmer avec l anglais\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "# initialiser la liste des mots a stemmer\n",
    "words = ['leaf', 'leaves', 'booking', 'writing','completed', 'stemming', 'skies']\n",
    "\n",
    "# stemmer le mot\n",
    "stemmer_word = [stemmer.stem(word) for word in words]\n",
    "stemmer_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining similar words – lemmatization\n",
    "La différence est que la lemmatisation nous fournit un vrai mot, c'est-à-dire sa forme canonique(forme de base). Par exemple, le lemme du mot cats est cat, et le lemme du mot ran est run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['duck', 'goose', 'cat', 'book']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the NLTK WordNet lemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# initialise lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# initialiser la liste des mots a lemmatizer\n",
    "words = ['duck', 'geese', 'cats', 'books']\n",
    "\n",
    "# lemmatizer le mot\n",
    "lemmatizer_word = [lemmatizer.lemmatize(word) for word in words]\n",
    "lemmatizer_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
